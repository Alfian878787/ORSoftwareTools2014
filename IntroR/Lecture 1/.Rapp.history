require(stats)
lm_test <- lm(rating ~ complaints, data=attitude)
print(summary(lm_test))
lm(formula = rating ~ complaints, data = attitude)
source("Assignment.R")
getwd()
setwd("~/Desktop/")
setwd("~/Dropbox/MIT ORC/IAP 2014/Lecture 1/")
source("Assignment.R")
3^(6-4)
22/7
16^(1/4)
6*9 ==
42
6*9 ==
43
6*9 ==
54
sqrt(2)
abs(-2)
sin(pi/2)
cos(0)
exp(-1)
(1 - 1/100)^100
log(exp(1))
help(log)
?log
x <- 2^3
y = 6
x
y
print(x)
print(y)
z <- seq(1:10)
z[5]
sum(z)
double_z <- z^2
locations = c("Davis", "Porter", "Harvard", "Central", "Kendall")
capacities = c(10, 15, 20, 15, 25)
cbind(locations, capacities)
rbind(locations, capacities)
df1 = data.frame(locations, capacities)
capacities = c(15, 10, 10, 5, 5)
df2 = data.frame(locations, capacities)
df.bikes = rbind(df1, df2)
class(locations)
str(locations)
class(capacities)
str(capacities)
class(df.bikes)
str(df.bikes)
df.bikes
df.bikes$locations
summary(df.bikes)
summary(df.bikes$locations)
bikesKendall = subset(df.bikes, locations=="Kendall")
bikesKendall
sum(bikesKendall$capacities)
CEOcomp = read.csv(file = "CEOcomp.csv", header = TRUE)
str(CEOcomp)
CEOcomp$Years
CEOcomp$MBA
attach(CEOcomp)
Years
MBA
detach(CEOcomp)
mean(CEOcomp$Years)
sd(CEOcomp$Years)
summary(CEOcomp$Years)
plot(CEOcomp$Years, CEOcomp$TotalCompensation)
plot(CEOcomp$Years, CEOcomp$TotalCompensation, main="Total Compensation by Year", xlab = "Years of Experience", ylab = "Total Compensation (thousand USD)")
library(help = "graphics")
tapply(CEOcomp$Years, CEOcomp$MBA, mean)
table(CEOcomp$Years, CEOcomp$MBA)
save.image("eg.RData")
save(CEOcomp, file = "CEOcomp.RData")
CEO.linReg <- lm(TotalCompensation ~ Years + ChangeStockPrice + ChangeCompanySales + MBA, data = CEOcomp)
summary(CEO.linReg)
CEO.linReg$coefficients
CEO.linReg$residuals
confint(CEO.linReg, level = 0.95)
cor(CEOcomp$TotalCompensation, CEOcomp$Years)
cor(CEOcomp)
cor.test(CEOcomp$TotalCompensation, CEOcomp$Years)
TitanicPassengers = read.csv("TitanicPassengers.csv")
str(TitanicPassengers)
install.packages("caTools")
library(caTools)
split <- sample.split(TitanicPassengers$Survived, SplitRatio = 0.6)
TitanicTrain <- TitanicPassengers[split, 1:5]
TitanicTest <- TitanicPassengers[!split, 1:5]
Titanic.logReg = glm(Survived ~ Class + Age + Sex, data = TitanicTrain, family = binomial)
summary(Titanic.logReg)
Titanic.logPred = predict(Titanic.logReg, type = "response")
table(TitanicTrain$Survived, round(Titanic.logPred))
Titanic.logPredTest = predict(Titanic.logReg, newdata = TitanicTest, type = "response")
test.table <- table(TitanicTest$Survived, round(Titanic.logPredTest))
test.table
sum(diag(test.table))/nrow(TitanicTest)
library(rpart)
Titanic.CART = rpart(Survived ~ Class + Age + Sex, data = TitanicTrain, method = "class", control = rpart.control(minbucket = 10))
plot(Titanic.CART)
text(Titanic.CART, pretty = 0)
Titanic.CARTpredTest = predict(Titanic.CART, newdata = TitanicTest, type = "class")
CARTpredTable <- table(TitanicTest$Survived, Titanic.CARTpredTest)
CARTpredTable
sum(diag(CARTpredTable))/nrow(TitanicTest)
CEOcomp.CART = rpart(TotalCompensation ~ Years + ChangeStockPrice + ChangeCompanySales + MBA, data = CEOcomp, method = "anova", control = rpart.control(minsplit = 5))
predict(CEOcomp.CART)
CEOcomp$TotalCompensation
library(randomForest)
Titanic.forest = randomForest(Survived ~ Class + Age + Sex, data = TitanicTrain, nodesize = 10, ntree = 200)
str(TitanicTrain$Survived)
TitanicTrain$Survived <- factor(TitanicTrain$Survived)
TitanicTest$Survived <- factor(TitanicTest$Survived)
Titanic.forest = randomForest(Survived ~ Class + Age + Sex, data = TitanicTrain, nodesize = 10, ntree = 200)
Titanic.forestPred = predict(Titanic.forest, newdata = TitanicTest)
forest.table <- table(TitanicTest$Survived, Titanic.forestPred)
forest.table
sum(diag(forest.table))/nrow(TitanicTest)
data(iris)
str(iris)
IrisDist = dist(iris[1:4], method = "euclidean")
IrisHC = hclust(IrisDist, method = "ward")
plot(IrisHC)
rect.hclust(IrisHC, k = 3, border = "red")
IrisHCGroups = cutree(IrisHC, k = 3)
table(iris$Species, IrisHCGroups)
tapply(iris$Petal.Length, IrisHCGroups, mean)
IrisKMC = kmeans(iris[1:4], centers = 3, iter.max = 100)
IrisKMCGroups = IrisKMC$cluster
table(iris$Species, IrisKMCGroups)
?seq
seq(from = 2, to = 20, by = 2)
seq(1:10)
evens <- evens * 2
evens <- seq(1:10)
evens <- evens * 2
evens
hist(CEOcomp$Years, main = "Title", xlab = "x-axis")
CEOcomp = read.csv(file = "CEOcomp.csv", header = TRUE)
hist(CEOcomp$Years, main = "Title", xlab = "x-axis")
bikes = read.csv("stations.csv")
str(bikes)
mean(bikes$lat)
mean(bikes$lng)
plot(bikes$lat, bikes$lng, xlab = "latitude", ylab = "longitude", main = "title")
plot(bikes$lng, bikes$lat, xlab = "longitude", ylab = "latitude", main = "title")
?round
round(25.26, digits = 1)
bikes$lng2 <- round(bikes$lng, digits = 2)
bikes$lat2 <- round(bikes$lat, digits = 2)
table(bikes$lng2, bikes$lat2)
letters = read.csv("LettersBinary.csv")
str(letters)
split = sample.split(letters, SplitRatio = 0.6)
split = sample.split(letters$Letter, SplitRatio = 0.6)
library(caTools)
split = sample.split(letters$Letter, SplitRatio = 0.6)
?plot
CEO.linReg <- lm(TotalCompensation ~ Years + ChangeStockPrice + ChangeCompanySales + MBA, data = CEOcomp)
summary(CEO.linReg)
CEO.linReg$coefficients
CEO.linReg$residuals
confint(CEO.linReg, level = 0.95)
cor(CEOcomp$TotalCompensation, CEOcomp$Years)
cor(CEOcomp)
cor.test(CEOcomp$TotalCompensation, CEOcomp$Years)
Titanic.logReg = glm(Survived ~ Class + Age + Sex, data = TitanicTrain, family = binomial)#
summary(Titanic.logReg)#
#
# Compute predicted probabilities on training data#
Titanic.logPred = predict(Titanic.logReg, type = "response")#
#
# Build a classification table to check accuracy on #
# training set. Note that due to randomness of split, #
# classification matrices may be slightly different#
table(TitanicTrain$Survived, round(Titanic.logPred))
TitanicPassengers = read.csv("TitanicPassengers.csv")#
str(TitanicPassengers)#
#
# We first need to install a package to help#
# us split the data.  Note that this only#
# needs to be done once per machine!#
install.packages("caTools")#
#
# Now load the library.  This needs to be done#
# every time you wish to use the library.#
library(caTools)#
# Now split the dataset into training and testing#
split <- sample.split(TitanicPassengers$Survived, SplitRatio = 0.6)#
TitanicTrain <- TitanicPassengers[split, 1:5]#
TitanicTest <- TitanicPassengers[!split, 1:5]#
#
##########################
## LOGISTIC REGRESSION ###
##########################
#
# Run a logistic regression using general linear model#
Titanic.logReg = glm(Survived ~ Class + Age + Sex, data = TitanicTrain, family = binomial)#
summary(Titanic.logReg)#
#
# Compute predicted probabilities on training data#
Titanic.logPred = predict(Titanic.logReg, type = "response")#
#
# Build a classification table to check accuracy on #
# training set. Note that due to randomness of split, #
# classification matrices may be slightly different#
table(TitanicTrain$Survived, round(Titanic.logPred))
table(CEOcomp$Years, CEOcomp$MBA)
